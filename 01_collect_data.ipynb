{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c5ffa4-6089-475f-887b-30ac9ba943bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "import requests_cache\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio of stocks interested\n",
    "MAG7 = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"META\", \"NVDA\", \"TSLA\"] # the portfolio I am interested in is the magnificent 7\n",
    "MARKET = \"^GSPC\"  # using S&P 500 Index as market info (e.g. realized \"market\" volatility)\n",
    "RF_SERIES = \"TB3MS\"  # 3-Month Treasury Bill, Secondary Market Rate (%), monthly from FRED, as the risk-free return r_f\n",
    "\n",
    "# Range of dates interested\n",
    "START_DATE = \"2023-01-01\"\n",
    "END_DATE = \"20250908\"  # if 'None', it means today\n",
    "\n",
    "DATA_DIR = Path(os.path.abspath('')).resolve() / \"data\"\n",
    "PRICES_RAW = DATA_DIR / \"prices\" / \"raw\"\n",
    "PRICES_DERIVED = DATA_DIR / \"prices\" / \"derived\"\n",
    "MARKET_DIR = DATA_DIR / \"market\"\n",
    "RF_DIR = DATA_DIR / \"risk_free\"\n",
    "\n",
    "requests_cache.install_cache(\"yfinance_cache\", expire_after=300) # create a cache called 'yfinance_cache.sqlite' for the data fetched for faster re-runs while developing \n",
    "# both yfinance (Yahoo) and pandas-datareader benefit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e974f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some util functions\n",
    "\n",
    "def ensure_dirs():\n",
    "    \"\"\"\n",
    "    Create the directories to store the info\n",
    "    \"\"\"\n",
    "    for d in [PRICES_RAW, PRICES_DERIVED, MARKET_DIR, RF_DIR]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _normalize_dates(start, end):\n",
    "    start = pd.Timestamp(start, tz=timezone.utc).tz_convert(None)\n",
    "    end = pd.Timestamp.today(tz=timezone.utc).tz_convert(None) if end is None else pd.Timestamp(end, tz=timezone.utc).tz_convert(None)\n",
    "    return start, end\n",
    "\n",
    "def fetch_daily_panel(tickers, start, end):\n",
    "    \"\"\"\n",
    "    Returns a MultiIndex-columns DataFrame:\n",
    "    columns: (field, ticker) for fields in ['Open','High','Low','Close','Adj Close','Volume']\n",
    "    index: datetime (UTC-naive)\n",
    "    \"\"\"\n",
    "    df = yf.download(\n",
    "        tickers=tickers,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        auto_adjust=False,   # keep raw + Adj Close; we’ll use Adj Close for returns\n",
    "        actions=False,\n",
    "        progress=False,\n",
    "        group_by=\"column\"\n",
    "    )\n",
    "    # yfinance returns columns as a single-level when 1 ticker; unify shape:\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        pass\n",
    "    else:\n",
    "        # single ticker -> promote to MultiIndex\n",
    "        df = pd.concat({tickers[0]: df}, axis=1)\n",
    "\n",
    "    # Reorder to (field, ticker) for easier selection later\n",
    "    df = df.swaplevel(axis=1).sort_index(axis=1)\n",
    "    # Remove timezone if present\n",
    "    df.index = pd.to_datetime(df.index, utc=True).tz_convert(None)\n",
    "    return df\n",
    "\n",
    "def compute_daily_returns(prices_panel):\n",
    "    \"\"\"\n",
    "    Compute percentage returns from Adj Close for each ticker.\n",
    "    Returns a wide DataFrame with tickers as columns.\n",
    "    \"\"\"\n",
    "    adj = prices_panel.xs('Adj Close', axis=1, level='Price').copy()\n",
    "    rets = adj.pct_change().dropna(how=\"all\")\n",
    "    return rets\n",
    "\n",
    "def save_df(df, path_no_ext):\n",
    "    \"\"\"\n",
    "    Save both parquet and csv (UTF-8).\n",
    "    \"\"\"\n",
    "    df.to_parquet(f\"{path_no_ext}.parquet\")\n",
    "    df.to_csv(f\"{path_no_ext}.csv\", index=True)\n",
    "\n",
    "def fetch_market_series_and_realized_vol(start, end):\n",
    "    \"\"\"\n",
    "    Fetch ^GSPC daily, compute within-month realized variance & volatility:\n",
    "        σ2_t = Var_{daily in month t}(r_d)\n",
    "        σ_t  = sqrt(σ2_t)\n",
    "    Also compute inverse measures: inv_sigma_t = 1/σ_t and inv_var_t = 1/σ2_t\n",
    "    Returns a month-end indexed DataFrame.\n",
    "    \"\"\"\n",
    "    mkt = yf.download(MARKET, start=start, end=end, auto_adjust=True, progress=False)\n",
    "    if mkt.empty:\n",
    "        raise RuntimeError(\"Failed to fetch market series.\")\n",
    "    mkt.index = pd.to_datetime(mkt.index, utc=True).tz_convert(None)\n",
    "    price = (mkt.xs('Close', axis=1, level='Price') if isinstance(mkt.columns, pd.MultiIndex) else mkt['Close']).squeeze()\n",
    "    \n",
    "    # Within-month realized variance (sample variance of daily returns)\n",
    "    # Use ddof=1 to match sample variance convention\n",
    "    ret = price.pct_change()\n",
    "    rv = ret.groupby(pd.Grouper(freq=\"ME\")).agg(lambda s: s.dropna().var(ddof=1))\n",
    "    \n",
    "    sigma2 = rv.rename(\"sigma2\")\n",
    "    sigma = sigma2.pow(0.5).rename(\"sigma\")\n",
    "    inv_sigma = (1.0 / sigma).replace([pd.NA, pd.NaT, float(\"inf\")], pd.NA).rename(\"inv_sigma\")\n",
    "    inv_sigma2 = (1.0 / sigma2).replace([pd.NA, pd.NaT, float(\"inf\")], pd.NA).rename(\"inv_sigma2\")\n",
    "    out = pd.concat([sigma2, sigma, inv_sigma, inv_sigma2], axis=1).dropna()\n",
    "    return out\n",
    "\n",
    "def fetch_rf_monthly(start, end):\n",
    "    \"\"\"\n",
    "    Fetch TB3MS (%) monthly from FRED and convert to monthly return:\n",
    "        rf_month = (1 + rate/100) ** (1/12) - 1\n",
    "    \"\"\"\n",
    "    # FRED returns month-end indexed series already\n",
    "    rf = pdr.DataReader(RF_SERIES, \"fred\", start, end)\n",
    "    rf.index = pd.to_datetime(rf.index, utc=True).tz_convert(None)\n",
    "    rf = rf.rename(columns={RF_SERIES: \"TB3MS_pct\"})\n",
    "    rf[\"rf_month\"] = (1.0 + rf[\"TB3MS_pct\"] / 100.0) ** (1.0 / 12.0) - 1.0\n",
    "    # Keep only month-end, drop NaNs\n",
    "    rf = rf.dropna()\n",
    "    return rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efbb5d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved files:\n",
      "- data\\prices\\raw\\daily_prices.parquet & .csv  (panel OHLCV)\n",
      "- data\\prices\\derived\\daily_returns.parquet & .csv  (AdjClose returns)\n",
      "- data\\market\\market_vol_monthly.parquet & .csv  (σ_t, σ2_t, 1/σ_t, 1/σ2_t)\n",
      "- data\\risk_free\\rf_monthly.parquet & .csv  (monthly rf returns)\n",
      "\n",
      "Shapes:\n",
      "  daily_prices   : (671, 42)\n",
      "  daily_returns  : (670, 7)\n",
      "  market_vol_m   : (33, 4)\n",
      "  rf_monthly     : (32, 2)\n"
     ]
    }
   ],
   "source": [
    "ensure_dirs() # create the directories needed\n",
    "start, end = _normalize_dates(START_DATE, END_DATE)\n",
    "\n",
    "# 1) Prices: MAG7 + save raw panel + daily returns\n",
    "tickers = MAG7.copy()\n",
    "prices_panel = fetch_daily_panel(tickers, start, end)\n",
    "save_df(prices_panel, PRICES_RAW / \"daily_prices\")\n",
    "\n",
    "daily_rets = compute_daily_returns(prices_panel)\n",
    "save_df(daily_rets, PRICES_DERIVED / \"daily_returns\")\n",
    "\n",
    "# 2) Market: realized monthly vol/var + inverses\n",
    "market_vol = fetch_market_series_and_realized_vol(start, end)\n",
    "save_df(market_vol, MARKET_DIR / \"market_vol_monthly\")\n",
    "\n",
    "# 3) Risk-free: monthly return\n",
    "rf = fetch_rf_monthly(start, end)\n",
    "save_df(rf, RF_DIR / \"rf_monthly\")\n",
    "\n",
    "# 4) Quick sanity print\n",
    "print(\"\\nSaved files:\")\n",
    "print(f\"- {Path(*PRICES_RAW.parts[PRICES_RAW.parts.index('data'):])/'daily_prices.parquet'} & .csv  (panel OHLCV)\")\n",
    "print(f\"- {Path(*PRICES_DERIVED.parts[PRICES_DERIVED.parts.index('data'):])/'daily_returns.parquet'} & .csv  (AdjClose returns)\")\n",
    "print(f\"- {Path(*MARKET_DIR.parts[MARKET_DIR.parts.index('data'):])/'market_vol_monthly.parquet'} & .csv  (σ_t, σ2_t, 1/σ_t, 1/σ2_t)\")\n",
    "print(f\"- {Path(*RF_DIR.parts[RF_DIR.parts.index('data'):])/'rf_monthly.parquet'} & .csv  (monthly rf returns)\")\n",
    "print(\"\\nShapes:\")\n",
    "print(\"  daily_prices   :\", prices_panel.shape)\n",
    "print(\"  daily_returns  :\", daily_rets.shape)\n",
    "print(\"  market_vol_m   :\", market_vol.shape)\n",
    "print(\"  rf_monthly     :\", rf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d340f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28553d-85db-402d-9c53-954005427eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
